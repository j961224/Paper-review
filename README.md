# Paper-review
하나하나씩 해보는 논문 리뷰!

* [Attention is all you need](https://github.com/j961224/Paper-review/tree/main/Transformer/Attention%20is%20all%20you%20need)


---

# To-Do


[A DEEP REINFORCED MODEL FOR ABSTRACTIVE SUMMARIZATION](https://arxiv.org/pdf/1705.04304.pdf) -> rl idea

[Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting](https://arxiv.org/pdf/1805.11080.pdf) -> rl idea2

[BETTER FINE-TUNING BY REDUCING REPRESENTATIONAL COLLAPSE](https://arxiv.org/pdf/2008.03156v1.pdf) -> r3f idea

[SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization 2021](https://arxiv.org/pdf/2106.01890.pdf) -> rerank idea?
